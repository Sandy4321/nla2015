{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 14: Toeplitz matrices + matrix functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mid-term test statistics\n",
    "<img src='test-stat.png' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Syllabus\n",
    "**Week 1:** Matrices, vectors, matrix/vector norms, scalar products & unitary matrices  \n",
    "**Week 2:** TAs-week (Strassen, FFT, a bit of SVD)  \n",
    "**Week 3:** Matrix ranks, singular value decomposition, linear systems, eigenvalues  \n",
    "**Week 4:** Matrix decompositions: QR, LU, SVD + test + structured matrices start  \n",
    "**Week 5:** Iterative methods, preconditioners, matrix functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap of the previous lecture\n",
    "- Concept of Incomplete LU/Incomplete Cholesky (ILU(k), ILUT, ILU2)\n",
    "- A brief note about algebraic multigrid (no details, because we need PDEs for the general multigrid concept) \n",
    "- Iterative methods for other NLA problems (SVD, eigenvalue problems)\n",
    "- Other than sparse: Toeplitz matrices, FFT, circulant matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today lecture\n",
    "\n",
    "Today we have (again!) a very ambitious plan:\n",
    "\n",
    "- Direct methods for Toeplitz matrices, Gohberg-Semencul formula\n",
    "- Iterative methods for Toeplitz matrices\n",
    "- Circulant preconditioners\n",
    "- Two-dimensional (BTTB) matrices\n",
    "- Matrix functions: basic concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reminder\n",
    "First, we will remind the last part of the Tuesday lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Toeplitz matrices/circulant: one slide from last lecture\n",
    "\n",
    "A matrix is called **Toeplitz** if its elements are defined as\n",
    "\n",
    "$$a_{ij} = t_{i - j}.$$\n",
    "\n",
    "A Toeplitz matrix is completely defined by its first column and first row (i.e., $2n-1$ parameters).\n",
    "\n",
    "It can also be multiplied by vector fast using circulant embedding and FFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Low displacement rank structure\n",
    "\n",
    "The Toeplitz matrices belong to a more general class of **low displacement rank** matrices.\n",
    "\n",
    "Define the **scaled periodic shift matrix** \n",
    "\n",
    "$Z_e$ that takes the vector $x$ and transforms it to a vector\n",
    "\n",
    "$$Z_e x = \\begin{bmatrix}\n",
    "e x_{n-1} \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_{n-2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "What is the matrix form of this linear operator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Shift matrices, displacement matrices and Toeplitz matrices\n",
    "\n",
    "Given a Toeplitz matrix $T$, we select any $e, f$ such that $ef \\ne 1$ and define the displacement operator as\n",
    "\n",
    "$$L(T) = Z_e T - T Z_f.$$\n",
    "\n",
    "For a Toeplitz matrix, $L(T)$ has **rank 2** (it has only first row and last column non-zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "n = 5 \n",
    "c = np.zeros(n)\n",
    "c[0] = -2\n",
    "c[1] = 1\n",
    "T = sp.linalg.toeplitz(c, c)\n",
    "e = 0.5\n",
    "f = 0.5\n",
    "def Z_shift(e):\n",
    "    return  np.diag(np.ones(n-1), -1)  + e * np.diag(np.ones(1), n-1)\n",
    "\n",
    "Z1 = Z_shift(e)\n",
    "Z2 = Z_shift(f)\n",
    "\n",
    "print Z1.dot(T) - T.dot(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What about the inverse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "n = 5 \n",
    "c = np.zeros(n)\n",
    "c[0] = -2\n",
    "c[1] = 1\n",
    "T = sp.linalg.toeplitz(c, c)\n",
    "e = 0.5\n",
    "f = 0.5\n",
    "def Z_shift(e):\n",
    "    return  np.diag(np.ones(n-1), -1)  + e * np.diag(np.ones(1), n-1)\n",
    "\n",
    "Z1 = Z_shift(e)\n",
    "Z2 = Z_shift(f)\n",
    "\n",
    "Tinv = np.linalg.inv(T)\n",
    "\n",
    "p1 = Z1.dot(Tinv) - Tinv.dot(Z2)\n",
    "np.linalg.svd(p1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Small displacement rank: definition\n",
    "\n",
    "The matrix is said to be of **displacement rank $r$** with respect to the pair of generators \n",
    "\n",
    "$Z_e, Z_f$, if\n",
    "\n",
    "$$L(T) = Z_e T - T Z_f = GH^{\\top},$$\n",
    "\n",
    "where $G$ is $n \\times r$ and $H$ is $n \\times r$.\n",
    "\n",
    "It is similar to \"discrete derivative\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Theorem on the inverse structure\n",
    "\n",
    "Let $T$ satisfy\n",
    "\n",
    "$$Z_e T - T Z_f = GH ^{\\top},$$\n",
    "\n",
    "and let it be invertible.\n",
    "\n",
    "Then we have\n",
    "\n",
    "$$T^{-1} (Z_e T - T Z_f) T^{-1} = T^{-1} Z_e - Z_f T^{-1} = T^{-1} G H^{\\top} T^{-1},$$\n",
    "\n",
    "i.e. the inverse has **small displacement rank** with the reversed pair of generators $Z_e, Z_f$ (why?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recovering a matrix from the displacement representation\n",
    "\n",
    "Does the low-rank representation after the displacement operator describe the structure?\n",
    "\n",
    "I.e. we need to solve the equation of the form\n",
    "\n",
    "\n",
    "$$Z_e T - T Z_f = GH^{\\top} = B$$\n",
    "\n",
    "For a given right-hand side.\n",
    "\n",
    "This is a linear system of equations in disguise! (Do you see that this is a linear system? What is the size of this linear system?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sylvester equation\n",
    "The equation above is a special case of the **Sylvester matrix equation** which has the general form\n",
    "\n",
    "$$AX - X B = C,$$\n",
    "\n",
    "with $A$, $B$ and $C$ given.\n",
    "\n",
    "In general, this is a linear system with $\\mathcal{O}(n^2)$ unknowns, and the computational cost is expected to be $n^6$.\n",
    "\n",
    "Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solving Sylvester equation by the reduction to triangular form\n",
    "\n",
    "The Sylvester equation, in general, is solved with the help of the matrix decompositions.\n",
    "\n",
    "Reduce the matrix $B$ into the triangular form:\n",
    "\n",
    "$$B = U T U^*.$$\n",
    "\n",
    "Then we have\n",
    "\n",
    "$$A X - X U T U^* =C, \\quad A Y - Y T = C U, \\quad Y = X U,$$\n",
    "\n",
    "and solving the equation with triangular matrix $B$ is **easy** (let us check it on whiteboard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back to the particular case\n",
    "\n",
    "For the particular case, we have\n",
    "$$Z_e T - T Z_f = GH^{\\top} = B,$$\n",
    "\n",
    "and the solution is given by\n",
    "\n",
    "$$ (e - f) T = \\sum_{j = 1}^r Z_e(g_j) Z_f( J h_j), $$\n",
    "\n",
    "where $Z_e$ is the **e-scaled circulant** generated by the vector, and $g_j$, and $h_j$ are the columns of the matrices $G$ and $H$,\n",
    "\n",
    "and $J$ is the **per-identity matrix** (which has ones on the anti-diagonal).\n",
    "\n",
    "For details, see [the paper by Victor Pan et. al.](http://ac.els-cdn.com/S0024379501003366/1-s2.0-S0024379501003366-main.pdf?_tid=c532e56a-680e-11e5-81a5-00000aab0f01&acdnat=1443685015_d1c190dd112773e7479235b435da3b7e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gohberg-Semencul formula\n",
    "\n",
    "Based on this idea and for the special case when $e = 0, f \\rightarrow \\inf$, we get the following famous formula for the inverse of the Toeplitz matrices as a sum \n",
    "of two products of **triangular** Toeplitz matrices:\n",
    "\n",
    "Let $A$ be a Toeplitz matrix, and\n",
    "\n",
    "$$A \\begin{bmatrix} x_0 \\\\ x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix}=\\begin{bmatrix} 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix},\n",
    "\\quad \n",
    "A \\begin{bmatrix} y_0 \\\\ y_1 \\\\ \\vdots \\\\ y_n \\end{bmatrix}=\\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "then \n",
    "\n",
    "$$A^{-1} = \\frac{1}{x_0} \\begin{bmatrix} x_0 & 0 & \\ldots & 0 \\\\ x_1 & x_0 & 0 & \\ldots \\\\ \\ldots & \\ldots \\\\ x_n & \\ldots & \\ldots & x_0 \\end{bmatrix}\\begin{bmatrix} u_0 & u_1 & \\ldots & 0 \\\\ 0 & u_0 & u_1 & \\ldots \\\\ \\ldots & \\ldots \\\\ 0 & \\ldots & \\ldots & u_0 \\end{bmatrix}-\\frac{1}{x_0} \\begin{bmatrix} 0 & 0 & \\ldots & 0 \\\\ y_0 & 0 & 0 & \\ldots \\\\ y_1 & y_0 & \\ldots  \\\\ \\ldots & \\ldots & \\\\ y_{n-1} & \\ldots & y_0 & 0 \\end{bmatrix}\\begin{bmatrix} 0 & v_0 & \\ldots & 0 \\\\ 0 & 0 & v_0 & v_1 \\\\ \\ldots & \\ldots   \\\\ \\ldots & \\ldots & \\ldots & v_0 \\\\ 0 & \\ldots & \\ldots & 0\\end{bmatrix},$$\n",
    "\n",
    "where $u_y = y_{n-i}, \\quad v_i = x_{n-i}$.\n",
    "\n",
    "The main meaning: the inverse can be recovered from **the first column** and the **last column** of the matrix.\n",
    "\n",
    "For details, I refer to the book by Tyrtyshnikov \"Brief introduction to numerical analysis\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fast and superfast direct methods\n",
    "\n",
    "For many years, these formulas gave rise to the fast $\\mathcal{O}(n^2)$ and superfast $\\mathcal{O}(n \\log n)$ methods for Toeplitz matrices.\n",
    "\n",
    "The basic idea is that you use **augmentation method**. \n",
    "\n",
    "Consider that you have computed the **inverse** of a $(n-1) \\times (n-1)$ block of the Toeplitz matrix.\n",
    "\n",
    "You only need to store two vectors to represent the inverse.\n",
    "\n",
    "Then, the bigger matrix can be written in the block form.\n",
    "\n",
    "$$T_n = \\begin{bmatrix} T_{n-1} & a \\\\ b^{\\top} & c \\end{bmatrix}.$$\n",
    "\n",
    "We only need to recompute the last and the first column!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recomputing the last and the first columns\n",
    "\n",
    "Let us split the vector as \n",
    "\n",
    "$$x = \\begin{bmatrix} x_1 & x_2 \\end{bmatrix}.$$\n",
    "\n",
    "Then,\n",
    "\n",
    "\n",
    "$$T_{n-1} x_1 + a x_2 = e_1, \\quad b^{\\top} x_1 + c x_2 = 0.$$\n",
    "\n",
    "Or, \n",
    "\n",
    "$$  x_1 = T^{-1}_{n-1} e_1 - T^{-1}_n a x_2.$$\n",
    "\n",
    "Application of $T^{-1}_{n-1}$ costs $\\mathcal{O}(n \\log n)$ operations, \n",
    "\n",
    "thus $x_2$ will be recovered in the same number of operations as well. The total complexity is then $\\mathcal{O}(n^2 \\log n)$ operations.\n",
    "\n",
    "**Superfast algorithms** are obtained in terms of reducing the problem to the computations with polynomials and using **block** elimination  \n",
    "\n",
    "(in the Fourier style)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problems with fast and superfast methods\n",
    "\n",
    "- Main problem: superfast can be very unstable, since submatrices can be singular during the process.\n",
    "- Practical problems: No good open-source software (and in general with Toeplitz matrices, which is extremely bad)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Iterative methods\n",
    "\n",
    "Since direct methods can be really difficult to implement, people turned to **iterative methods**.\n",
    "\n",
    "A natural idea is to use **circulants** as preconditioners, since they are easy to invert.\n",
    "\n",
    "The first preconditioner was the preconditioner by **Raymond Chan and Gilbert Strang**, who proposed to take the first column of the matrix  \n",
    "\n",
    "and use it to generate the circulant.\n",
    "\n",
    "The second preconditioner is the **Tony Chan** preconditioner, which is also very natural: \n",
    "\n",
    "$$C = \\arg \\min_P \\Vert P - T \\Vert_F.$$\n",
    "\n",
    "A simple formula for the entries of $C$ can be derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "n = 100\n",
    "c = np.zeros(n)\n",
    "c[0] = -2\n",
    "c[1] = 1\n",
    "Tm = sp.linalg.toeplitz(c, c)\n",
    "\n",
    "\n",
    "c1 = sp.linalg.circulant(c) #Strang preconditioner\n",
    "Fmat = 1.0/np.sqrt(n) * np.fft.fft(np.eye(n)) #Poor man's Fourier matrix\n",
    "\n",
    "d2 = np.diag(Fmat.conj().dot(Tm).dot(Fmat))\n",
    "c2 = Fmat.dot(np.diag(d2)).dot(Fmat.conj().T)\n",
    "\n",
    "\n",
    "mat = np.linalg.inv(c1).dot(Tm)\n",
    "ev = np.linalg.eigvals(mat).real\n",
    "plt.plot(np.sort(ev), np.ones(n), 'o')\n",
    "plt.xlabel('Eigenvalues for Strang preconditioner')\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "\n",
    "mat = np.linalg.inv(c2).dot(Tm)\n",
    "ev = np.linalg.eigvals(mat).real\n",
    "plt.figure()\n",
    "plt.plot(np.sort(ev), np.ones(n), 'o')\n",
    "plt.xlabel('Eigenvalues for T. Chan Preconditioner')\n",
    "plt.gca().get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Better circulant preconditioner\n",
    "\n",
    "In fact, there is a much better one, and it is based on another idea.\n",
    "\n",
    "The matrix $C$ is a good preconditioner for a matrix $T$ if and only if\n",
    "\n",
    "$$T = C + R + E, $$\n",
    "\n",
    "where $R$ is **small rank**, $E$ is **small norm**.\n",
    "\n",
    "You can use (in a non-trivial way) this formulation to get  **optimal circulant preconditioner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Yet another way (and probably the best)\n",
    "\n",
    "This part is based on the ideas described in [the paper](http://amath.colorado.edu/faculty/martinss/Pubs/2004_toeplitz.pdf)\n",
    "\n",
    "Since circulant matrices are diagonalized by the Fourier transform, then what happens with a Toeplitz matrix after the FFT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "n = 100\n",
    "c = np.zeros(n)\n",
    "c = [1.0/(i - 0.5) for i in range(n)]\n",
    "\n",
    "Tm = sp.linalg.toeplitz(c, c)\n",
    "\n",
    "\n",
    "c1 = sp.linalg.circulant(c) #Strang preconditioner\n",
    "Fmat = 1.0/np.sqrt(n) * np.fft.fft(np.eye(n)) #Poor man's Fourier matrix\n",
    "\n",
    "T_tranf = Fmat.conj().dot(Tm).dot(Fmat)\n",
    "\n",
    "\n",
    "plt.contourf(T_tranf.real)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Main observation\n",
    "The off-diagonal part has small rank! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.linalg.svd(T_tranf[n/2:, :n/2])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exact formula for the FFT-transformed Toeplitz\n",
    "\n",
    "The FFT-transformed Toeplitz matrices has the form\n",
    "\n",
    "$$ \\widehat{T} = F^* T F, \\quad \\widehat{T}(m, n) = (v(m) - v(n)) \\phi(m - n), \\quad m \\ne n,$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "  v(n) = t(N + n) - t(n), \\quad \\phi(m-n) = \\frac{1}{2 \\sqrt{N} \\sin(\\pi(m- n)/N)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statement\n",
    "The matrices with big off-diagonal blocks that are of low-rank can efficient inverted. \n",
    "\n",
    "There are many algorithms, but for the 1D-case methods based on so-called **quasi-separable matrices** can be used to \n",
    "\n",
    "get $\\mathcal{O}(N \\log^{-1} \\varepsilon)$-complexity algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General scheme\n",
    "- Compute quasi-separable ($\\approx$ low-rank approximation of off-diagonal blocks in a hierarchical fashion) approximation of the Fourier transformed matrix $\\widehat{T}$\n",
    "- Apply efficient algorithms for the quasi-separable matrices to get a solution (the inverse of a quasi-separable matrix is a quasi-separable matrix).\n",
    "\n",
    "More details again not here, but in the FastPDE course, since these types of matrices frequently arise in the solution of PDEs and integral equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "-  The low-displacement rank is the right class for the Toeplitz matrices\n",
    "- Fast algorithms use augmentation method to iteratively recompute the inverse\n",
    "- The most efficient algorithm reduce to the block low-rank structure.\n",
    "- No efficient software!!! (probably we will write it some day)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some random notes\n",
    "The concept of **low displacement rank** is valid also for other classes of matrices.\n",
    "\n",
    "- Vandermonde matrix, $x^p_i$\n",
    "\n",
    "- Cauchy matrix, $\\frac{1}{x_i - y_j}$.\n",
    "\n",
    "Guess what are the **generators**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Block case\n",
    "\n",
    "A very interesting case is when you go from one-dimensional signals (say, audio) to two-dimensional and multidimensional case (i.e., images).\n",
    "\n",
    "Then it is natural to index the components of the vector by a pair of indices, $x_{i_1 i_2}$, and the elements of the matrix, \n",
    "\n",
    "acting on such \"vector\" by 4 indices, $A_{i_1 i_2 j_1 j_2}$, where $(i_1, i_2)$ enumerates the rows, while $(j_1, j_2)$ enumerates \n",
    "\n",
    "the columns of the matrix.\n",
    "\n",
    "Generalizations to higher dimensions are obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Block-Toeplitz-with-Toeplitz-Blocks\n",
    "\n",
    "In the two-dimensional case the shift invariance gives rise to **two-level** Toeplitz matrices:\n",
    "\n",
    "$$A_{i_1 i_2 j_1 j_2} = t_{(i_1 - j_1)(i_2 - j_2)}.$$\n",
    "\n",
    "They can be multiplied by vector fast by embedding into **two-level circulant matrices** (Block Circulant with Circulant Blocks, BCCB), which are diagonalized by two-dimensional FFT.\n",
    "\n",
    "$$C = F^*_2 D F_2, $$\n",
    "\n",
    "where $$F_2 = F \\otimes F.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solvers for BTTB matrices\n",
    "\n",
    "\n",
    "There are no direct $\\mathcal{O}(N \\log N)$ solvers for BTTB matrices.\n",
    "\n",
    "The fastest direct solver is the block version of the Gohberg-Semencul formula, which avoid one levels and has\n",
    "\n",
    "$\\mathcal{O}(N^{3/2})$ complexity.\n",
    "\n",
    "Typically, iterative methods are used. \n",
    "\n",
    "However, there are negative results on using **BCCB** preconditioners, \n",
    "\n",
    "[How to prove that preconditioner can not be superlinear](http://www.ams.org/mcom/2003-72-243/S0025-5718-03-01506-0/)\n",
    "\n",
    "but in practice they work quite good.\n",
    "\n",
    "There are **attempts** to do multigrid methods, but they are not very successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary-2\n",
    "\n",
    "- For 1D case there is a lot.\n",
    "- For the Block case one has to use iterative methods.\n",
    "- Research is ongoing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix functions\n",
    "Now, a little bit about matrix functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline of this part\n",
    "\n",
    "- What is a matrix function\n",
    "- Matrix exponential\n",
    "- (Some) applications\n",
    "\n",
    "Book to read: [Nick Higham, Functions of matrices](http://www.google.ru/books?hl=ru&lr=&id=2Wz_zVUEwPkC&oi=fnd&pg=PR3&dq=Higham+matrix+function&ots=pTt6fpLGRX&sig=DgUuX-SpBZGin8CFUo-4MYnOcHE&redir_esc=y#v=onepage&q=Higham%20matrix%20function&f=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a matrix function?\n",
    "A matrix function is a function of a matrix. A matrix function **is not** a function, applied to the elements!\n",
    "\n",
    "I.e., $B = \\sqrt{A}$ **does not mean** that $B_{ij} = \\sqrt{A}_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as sla \n",
    "\n",
    "A = 2 * np.eye(2)\n",
    "A = np.array([[4, 4], [4, 4]])\n",
    "sla.funm(A, lambda x: np.sqrt(x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The simplest matrix function: matrix polynomial\n",
    "\n",
    "It is very easy to define a matrix polynomial as  \n",
    "$$\n",
    " P(A) = \\sum_{k=0}^n c_k A^k.\n",
    "$$\n",
    "**Side-note:** [Hamilton-Cayley theorem](https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem) states that $F(A) = 0$ where $F(\\lambda) = \\det(A - \\lambda I)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix polynomials as building blocks\n",
    "We can define a function of the matrix by **Taylor series**:  \n",
    "$$\n",
    "   f(A) = \\sum_{k=0}^{\\infty} c_k A^k.\n",
    "$$\n",
    "The convergence is understood as the convergence in some **matrix norm**.  \n",
    "\n",
    "Example of such series is the **Neumann series**  \n",
    "$$\n",
    "  (I - F)^{-1} = \\sum_{k=0}^{\\infty} F^k,\n",
    "$$\n",
    "which is well defined for $\\rho(F) < 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix exponential series\n",
    "The most well-known matrix function is **matrix exponential**. In the scalar case,  \n",
    "$$\n",
    "   e^x = 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6} + \\ldots = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!},\n",
    "$$\n",
    "and it directly translates to the matrix case:  \n",
    "$$\n",
    "    e^A = \\sum_{k=0}^{\\infty} \\frac{A^k}{k!},\n",
    "$$\n",
    "the series that always converges (why?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why matrix exponential is important\n",
    "A **lot of** practical problems are reduced to a system of linear ODEs of the form  \n",
    "$$\n",
    "   \\frac{dy}{dt} = Ay, \\quad y(0) = y_0.\n",
    "$$\n",
    "The formal solution is given by $y(t) = e^{At} y_0$, so if we know  \n",
    "\n",
    "$e^{At}$ (or can compute matrix-by-vector product fast) there is a big gain over the  \n",
    "\n",
    "time-stepping schemes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to compute matrix functions?\n",
    "\n",
    "See [C. Van Loan, C. Moler, Nineteen Dubious Ways to Compute the Exponential of a Matrix, Twenty-Five Years Later](http://www.cs.cornell.edu/cv/researchpdf/19ways+.pdf)\n",
    "\n",
    "The simplest way is to diagonalize the matrix:  \n",
    "$$\n",
    "  A = S \\Lambda S^{-1}.\n",
    "$$\n",
    "where the columns of $S$ are **eigenvectors** of the matrix $A$,  then  \n",
    "\n",
    "$$\n",
    "   F(A) = S F(\\Lambda) S^{-1}.\n",
    "$$\n",
    "Problem: **diagonalization can be unstable!** (and not every matrix is diagonalizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us look how matrices are diagonalizable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "eps = 0.5\n",
    "p = 4\n",
    "a = np.eye(p)\n",
    "for i in xrange(p-1):\n",
    "    a[i, i+1] = 1\n",
    "    \n",
    "a[p-1, 2] = eps\n",
    "a = np.array(a)\n",
    "val, vec = np.linalg.eig(a)\n",
    "#print a\n",
    "print np.linalg.norm(a - vec.dot(np.diag(val)).dot(np.linalg.inv(vec)))\n",
    "#print 'S * D * S^{-1}:' \n",
    "#print vec.dot(np.diag(val)).dot(np.linalg.inv(vec))\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can compute a function for **perturbed Jordan block.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "eps = 1e-14\n",
    "p = 5\n",
    "a = np.eye(p)\n",
    "for i in xrange(p-1):\n",
    "    a[i, i+1] = 1\n",
    "    \n",
    "a[p-1, 0] = eps\n",
    "a = np.array(a)\n",
    "val, vec = np.linalg.eig(a)\n",
    "print np.linalg.norm(a - vec.dot(np.diag(val)).dot(np.linalg.inv(vec)))\n",
    "\n",
    "fun = lambda x: np.exp(x)\n",
    "\n",
    "#Using diagonalization\n",
    "fun_diag = vec.dot(np.diag(fun(val))).dot(np.linalg.inv(vec))\n",
    "\n",
    "\n",
    "#Using Schur\n",
    "import scipy\n",
    "fun_m = scipy.linalg.expm(a)\n",
    "np.linalg.norm(fun_m - fun_diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How funm function works\n",
    "The exponential of a matrix is a special function, so there are special methods for its computation.  \n",
    "\n",
    "For a general function,  there is a beautiful **Schur-Parlett algorithm**, which is based on the **Schur theorem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Schur-Parlett algorithm\n",
    "\n",
    "Given a matrix $A$ we want to compute $F(A)$, and we only can evaluate $F$ at **scalar points**.  \n",
    "First, we reduce $A$ to the **triangular form** as  \n",
    "$$\n",
    "   A = U T U^*.\n",
    "$$\n",
    "Therefore,  $F(A)=U F(T) U^*$\n",
    "\n",
    "We only need to compute the function of triangular matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing functions of triangular matrices\n",
    "We know values on the diagonals:  \n",
    "and $$F_{ii} = F(T_{ii}),$$\n",
    "and also we know that\n",
    "$$F T = T F,$$\n",
    "and we get\n",
    "\n",
    "$$f_{ij} = t_{ij} \\frac{f_{ii} - f_{jj}}{t_{ii} - t_{jj}} + \\sum_{k=i+1}^{j-1} \\frac{f_{ik} t_{kj} - t_{ki}f_{kj}}{t_{ii} - t_{jj}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary for this part\n",
    "- Matrix functions are not elementwise functions\n",
    "- For general functions, Schur-Parlett algorithm is the best.\n",
    "\n",
    "Next week we will finish the matrix functions part (matrix exponential in more details, sign function, square root) and also describe the cases where they appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Take home message\n",
    "\n",
    "- There are fast direct methods for Toeplitz but few people use them since there is no software\n",
    "- Typically, iterative methods are used\n",
    "- Know the definition of a BTTB matrix\n",
    "- A general understanding of what a matrix function is and how it can be computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next week\n",
    "Next week is the last study week. We will finish the matrix functions part and go for the \n",
    "\n",
    "\n",
    "**advanced topics.**\n",
    "\n",
    "They include: \n",
    "\n",
    "- Compressed sensing, L1-norm minimization, optimal design (A-optimality, D-optimality, maximum-volume principle in low-rank matrix factorization)\n",
    "- Multidimensional case: multilinear algebra "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        /*width:80%;*/\n",
       "        /*margin-left:auto !important;\n",
       "        margin-right:auto;*/\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\n",
       "    h2 {\n",
       "        font-family: 'Fenix', serif;\n",
       "    }\n",
       "    h3{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "\th4{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "       }\n",
       "    h5 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\t   \n",
       "    div.text_cell_render{\n",
       "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 1.2;\n",
       "        font-size: 120%;\n",
       "        /*width:70%;*/\n",
       "        /*margin-left:auto;*/\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\";\n",
       "\t\t\tfont-size: 90%;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 50pt;\n",
       "\t\tline-height: 110%;\n",
       "        color:#CD2305;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\t\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #CD2305;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    li {\n",
       "        line-height: 110%;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
